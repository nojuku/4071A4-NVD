The initial idea of an instrument was to identify objects on a desk with a camera and activate/modulate sound instances based on the object being present/absent as well as their scale and position. After working on this idea for some time i decided to put it away and work on something else - while object detection and sound generation part work it is tricky to tackle object tracking problem so the system understands the difference between the same object in the scene and a new one. It is something that can be done, but i will need more time to work on it in the future. The idea that i am submitting for A4 however is based on iPhone built in sensor space transmitted to Max with ZIGSIM iOS app via UDP/OSC. This app is very simple to set up and user gets to chose what sensor parameters they would like to stream. I chose to work with gravity, acceleration, touch (screen) and microphone level. On the Max side of things I have been lately looking into MC, watching Zicarelli's lectures on subject and really wanted to try something in that domain. While I am still learning the MC paradigm I really liked the idea of signal deviation - that is - for a synthesized MC wave you get to set a deviation parameters so that all channels play around a central frequency, but not precisely in the frequency. This allows for multiples of beats effects depending on the amounts of deviation. It is interesting because (again) it works out to sound different on different systems, which can be a problem or a possibility. For example when i played back the video recording on my iPhone the limitations of speakers changed the sound and made it new. 
In the control space the player has several inputs. First they can tweak the amount of deviation by sliding the finger up and down the screen. Second the intensity of the signal (volume) is controlled by the proximity of speaker and player. That is when you get closer to speaker the sound gets louder, when you get farther it gets quieter. That is achieved through the microphone level readings of the iPhone. Third there is a somewhat holistic approach system where the player can get three consecutive clicks if they position device in three different orientations in specific order- in particular screen down, screen up, and orthogonal to the ground. This is a system where you cannot unlock/play the next click sound unless you played the first one in the right orientation (screen up). Lastly i used acceleration to create a filtered noise wave sound - similar to the ocean wave, i think this part gives the most organic play feel of all - the player swings the phone across the space and the wave plays simoultaneously. 

Video link: https://drive.google.com/open?id=1-3k5zhP44SQVX6k-JBNx3ShK8rbiZwra&authuser=nojuku%40my.yorku.ca&usp=drive_fs
